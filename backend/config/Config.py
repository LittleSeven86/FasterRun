# coding=utf-8
# !/usr/bin/env python
# -*- coding:utf-8 -*-
# @FileName  :Config.py
# @Time      :2024/9/11 20:49
# @Author    :XiaoQi
import os
import typing
from os.path import abspath
from pathlib import Path

from pydantic.v1 import BaseSettings, AnyUrl

project_banner = """
,------.               ,--.                ,------.                  
|  .---',--,--. ,---.,-'  '-. ,---. ,--.--.|  .--. ',--.,--.,--,--,  
|  `--,' ,-.  |(  .-''-.  .-'| .-. :|  .--'|  '--'.'|  ||  ||      \ 
|  |`  \ '-'  |.-'  `) |  |  \   --.|  |   |  |\  \ '  ''  '|  ||  | 
`--'    `--`--'`----'  `--'   `----'`--'   `--' '--' `----' `--''--' 
"""

__version__ = "1.0"

project_desc = """
    ğŸ‰ FastRun ç®¡ç†å‘˜æ¥å£æ±‡æ€» ğŸ‰
"""

class Configs(BaseSettings):
    """
    é¡¹ç›®é…ç½®
    """
    PROJECT_DESC: str = project_desc
    PROJECT_BANNER: str = project_banner
    PROJECT_VERSION: str = __version__
    BASE_URL:AnyUrl = "http://127.0.0.1:8100"  # å¼€å‘ç¯å¢ƒ
    BASEDIR: str = os.path.join(abspath(os.path.dirname(os.path.abspath(__file__))))

    """
    æ—¥å¿—é…ç½®
    """
    LOGGER_DIR: str = "logs"  # æ—¥å¿—æ–‡ä»¶å¤¹å
    LOGGER_NAME: str = 'FastRun.log'  # æ—¥å¿—æ–‡ä»¶å  (æ—¶é—´æ ¼å¼ {time:YYYY-MM-DD_HH-mm-ss}.log)
    LOGGER_LEVEL: str = 'INFO'  # æ—¥å¿—ç­‰çº§: ['DEBUG' | 'INFO']
    LOGGER_ROTATION: str = "10 MB"  # æ—¥å¿—åˆ†ç‰‡: æŒ‰ æ—¶é—´æ®µ/æ–‡ä»¶å¤§å° åˆ‡åˆ†æ—¥å¿—. ä¾‹å¦‚ ["500 MB" | "12:00" | "1 week"]
    LOGGER_RETENTION: str = "7 days"  # æ—¥å¿—ä¿ç•™çš„æ—¶é—´: è¶…å‡ºå°†åˆ é™¤æœ€æ—©çš„æ—¥å¿—. ä¾‹å¦‚ ["1 days"]

    """
    æ•°æ®åº“é…ç½®
    """
    # DATABASE_URI: str = "sqlite+aiosqlite:///./sql_app.db?check_same_thread=False"  # Sqlite(å¼‚æ­¥)
    # DATABASE_URI: str = Field(..., env="MYSQL_DATABASE_URI")  # MySQL(å¼‚æ­¥)
    DATABASE_URI: str = "mysql+aiomysql://root:123456@localhost:3306/zerorunner"
    # DATABASE_URI: str = "postgresql+asyncpg://postgres:123456@localhost:5432/postgres"  # PostgreSQL(å¼‚æ­¥)
    DATABASE_ECHO: bool = False  # æ˜¯å¦æ‰“å°æ•°æ®åº“æ—¥å¿— (å¯çœ‹åˆ°åˆ›å»ºè¡¨ã€è¡¨æ•°æ®å¢åˆ æ”¹æŸ¥çš„ä¿¡æ¯)
    DATABASE_POOL_SIZE: int = 10    # é˜Ÿåˆ—æ± ä¸ªæ•°
    MAX_OVERFLOW: int = 10       # é˜Ÿåˆ—æ± æœ€å¤§æº¢å‡ºä¸ªæ•°
    POOL_PRE_PING:bool = True       # å°†å¯ç”¨è¿æ¥æ± â€œé¢„pingâ€åŠŸèƒ½ï¼Œè¯¥åŠŸèƒ½åœ¨æ¯æ¬¡ç­¾å‡ºæ—¶æµ‹è¯•è¿æ¥çš„æ´»è·ƒåº¦
    POOL_RECYCLE:int = 7200     # 2ä¸ªå°æ—¶å›æ”¶çº¿ç¨‹


    # redis
    # REDIS_URI: str = Field(..., env="jdbc:redis://localhost:6379/0")  # redis
    REDIS_URI: str = "redis://localhost:6379/0"


    # apié…ç½®
    API_PREFIX: str = "/api"  # æ¥å£å‰ç¼€


    # å¸¸é‡
    # å…¬å…±
    DEFAULT_PAGE = 1
    DEFAULT_PER_PAGE = 10
    DEFAULT_FAIL = -1

    # Cache Time
    CACHE_FIVE_SECONDS = 5
    CACHE_MINUTE = 60
    CACHE_THREE_MINUTE = 60 * 3
    CACHE_FIVE_MINUTE = 60 * 5
    CACHE_TEN_MINUTE = 60 * 10
    CACHE_HALF_HOUR = 60 * 30
    CACHE_HOUR = 60 * 60
    CACHE_THREE_HOUR = 60 * 60 * 3
    CACHE_TWELVE_HOUR = 60 * 60 * 12
    CACHE_DAY = 60 * 60 * 24
    CACHE_WEEK = 60 * 60 * 24 * 7
    CACHE_MONTH = 60 * 60 * 24 * 30

    # Cache
    TEST_USER_INFO = 'fastrun:user_token:{0}'  # ç”¨æˆ·tokenç¼“å­˜
    TEST_EXECUTE_SET = 'fastrun:test_execute_set:case:{}'  # ç”¨ä¾‹æ‰§è¡Œé›†åˆ
    TEST_EXECUTE_STATS = 'fastrun:test_execute_set:stats:{}'  # ç”¨ä¾‹æ‰§è¡Œç»Ÿè®¡
    TEST_EXECUTE_TASK = 'fastrun:test_execute_set:task:{}'  # è¿è¡Œä»»åŠ¡æ•°
    TEST_EXECUTE_PARAMETER = 'fastrun:test_execute_set:extract_parameter:{}'  # å˜é‡
    DATA_STRUCTURE_CASE_UPDATE = 'fastrun:data_structure:user:{}'  # æ•°æ®æ„é€ ç”¨æˆ·å˜æ›´çš„æ¥å£ä¿¡æ¯
    TEST_USER_LOGIN_TIME = 'fastrun:user_login_time:{}'  # æ•°æ®æ„é€ ç”¨æˆ·å˜æ›´çš„æ¥å£ä¿¡æ¯

    # æ€§èƒ½
    PREFORMANCE_RUN_STATUS = 'performance_test:status'
    PREFORMANCE_FREE = 0
    PREFORMANCE_INIT = 10
    PREFORMANCE_BUSY = 20
    PREFORMANCE_ABORT = 30

    PREFORMANCE_CODE = 'code'
    PREFORMANCE_SIGN_CODE = 'sign_code'

    THREAD_MAXMUM = 100
    RUN_NUMBER_MAXMUM = 1000000
    DEBUG_MAXMUM = 100

    API_PREFIX: str = "/api"  # æ¥å£å‰ç¼€
    STATIC_DIR: str = 'static'  # é™æ€æ–‡ä»¶ç›®å½•
    GLOBAL_ENCODING: str = 'utf8'  # å…¨å±€ç¼–ç 
    CORS_ORIGINS: typing.List[typing.Any] = ["*"]  # è·¨åŸŸè¯·æ±‚
    WHITE_ROUTER: list = ["/api/user/login", "/api/file","/api/user/register"]  # è·¯ç”±ç™½åå•ï¼Œä¸éœ€è¦é‰´æƒ

    # celery worker
    # broker_url: str = Field(..., env="CELERY_BROKER_URL")
    broker_url: str = "pyamqp://admin:123456@localhost:5672"
    # result_backend: str = Field(..., env="CELERY_RESULT_BACKEND")
    task_serializer: str = "pickle"
    result_serializer: str = "pickle"
    accept_content: typing.Tuple = ("pickle", "json",)
    task_protocol: int = 2
    timezone: str = "Asia/Shanghai"
    enable_utc: bool = False
    broker_connection_retry_on_startup: bool = True
    # å¹¶å‘å·¥ä½œè¿›ç¨‹/çº¿ç¨‹/ç»¿è‰²çº¿ç¨‹æ‰§è¡Œä»»åŠ¡çš„æ•°é‡ é»˜è®¤10
    worker_concurrency: int = 10
    # ä¸€æ¬¡é¢„å–å¤šå°‘æ¶ˆæ¯ä¹˜ä»¥å¹¶å‘è¿›ç¨‹æ•° é»˜è®¤4
    worker_prefetch_multiplier: int = 4
    # æ± å·¥ä½œè¿›ç¨‹åœ¨è¢«æ–°ä»»åŠ¡æ›¿æ¢ä¹‹å‰å¯ä»¥æ‰§è¡Œçš„æœ€å¤§ä»»åŠ¡æ•°ã€‚é»˜è®¤æ˜¯æ²¡æœ‰é™åˆ¶
    worker_max_tasks_per_child: int = 100
    # è¿æ¥æ± ä¸­å¯ä»¥æ‰“å¼€çš„æœ€å¤§è¿æ¥æ•° é»˜è®¤10
    broker_pool_limit: int = 10
    # ä¼ é€’ç»™åº•å±‚ä¼ è¾“çš„é™„åŠ é€‰é¡¹çš„å­—å…¸ã€‚è®¾ç½®å¯è§æ€§è¶…æ—¶çš„ç¤ºä¾‹ï¼ˆRedis å’Œ SQS ä¼ è¾“æ”¯æŒï¼‰
    result_backend_transport_options: typing.Dict[str, typing.Any] = {'visibility_timeout': 3600}
    worker_cancel_long_running_tasks_on_connection_loss: bool = True
    include: typing.List[str] = [
        # 'celery_worker.tasks.test_case',
        'celery_worker.tasks.common',
        'celery_worker.tasks.task_run',
        # 'celery_worker.tasks.ui_case',
    ]
    # task_queues = (
    #     Queue('default', routing_key='default'),
    #     Queue('ui_case', routing_key='ui_case'),
    #     Queue('api_case', routing_key='api_case'),
    # )

    #  job -A your_app worker -Q api_case,ui_case

    TEST_FILES_DIR: str = Path(__file__).parent.joinpath("static", "files").as_posix()
    PROJECT_ROOT_DIR: str = Path(__file__).parent.as_posix()

    task_run_pool: int = 3

    # job beat
    # beat_db_uri: str = Field(..., env="CELERY_BEAT_DB_URL")
    beat_db_uri: str = ""


    class Config:
        case_sensitive = True
        env_file = ".env"
        env_file_encoding = "utf-8"


config = Configs()
